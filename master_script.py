import asyncio
import os
import sys
import httpx
import re
import urllib.parse
import random
from playwright.async_api import async_playwright

# --- Read and write private scripts from environment variables ---
try:
Â  Â  with open("StreamBTW_temp.py", "w", encoding="utf-8") as f:
Â  Â  Â  Â  f.write(os.environ["STREAMBTW_SCRIPT"])
Â  Â  import StreamBTW_temp as StreamBTW

except KeyError as e:
Â  Â  print(f"Error: Required secret not found in environment. Missing: {e}", file=sys.stderr)
Â  Â  sys.exit(1)
except Exception as e:
Â  Â  print(f"Error importing one of the scripts: {e}", file=sys.stderr)
Â  Â  sys.exit(1)

# --- Output configuration ---
OUTPUT_FILE_DIR = "MyStuff"
OUTPUT_FILE_NAME = "MyStuff.m3u"
OUTPUT_FILE_PATH = os.path.join(OUTPUT_FILE_DIR, OUTPUT_FILE_NAME)

# --- Timezone configuration ---
TIMEZONES = ["Asia/Tokyo", "Australia/Sydney", "Asia/Dhaka", "Asia/Hong_Kong", "Asia/Singapore"]

# --- Remote M3U sources ---
NEW_SCRAPERS = {
Â  Â  "DDL": "https://raw.githubusercontent.com/pigzillaaa/daddylive/refs/heads/main/daddylive-channels.m3u8",
Â  Â  "LVN": "https://raw.githubusercontent.com/Love4vn/love4vn/df177668fda4e7dd5a7004b5987b0c304293aabe/output.m3u",
Â  Â  "A1X": "https://bit.ly/a1xstream",
Â  Â  "ZXIPTV": "https://raw.githubusercontent.com/ZXArkin/my-personal-iptv/0ca106073e1d7ec9fd9fe07d2467cdb8eed13b13/ZXIPTV.m3u"
}

# --- Filter keywords ---
FILTER_KEYWORDS = ['nfl', 'mlb', 'basketball', 'baseball', 'nba', 'mls',
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â 'American Football', 'rugby', 'liga', 'basket', 'Women', 'nba w', 'cricket']

# --- Extra filter keywords for BuddyChewChew ---
BDC_KEYWORDS = ["netflix", "primevideo+", "hulu"]

# --- LVN filter keywords ---
LVN_KEYWORDS = ["uk sky sports", "nz hd", "nz: sky", "bein sports english", "dstv:", "beinsports"]

# --- Fetch remote M3U (generic for DDL, A1X, etc.) ---
async def fetch_and_process_remote_m3u(url, source_name):
Â  Â  if source_name == "LVN":
Â  Â  Â  Â  return await fetch_lvn_streams(url)
Â  Â  print(f"Fetching and processing M3U from {url} (Source: {source_name})...", flush=True)
Â  Â  try:
Â  Â  Â  Â  async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
Â  Â  Â  Â  Â  Â  response = await client.get(url)
Â  Â  Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  Â  Â  content = response.text
Â  Â  Â  Â  Â  Â  lines = content.splitlines()
Â  Â  Â  Â  Â  Â  modified_lines = []
Â  Â  Â  Â  Â  Â  if not lines[0].strip().startswith("#EXTM3U"):
Â  Â  Â  Â  Â  Â  Â  Â  modified_lines.append("#EXTM3U")
Â  Â  Â  Â  Â  Â  stream_block = []
Â  Â  Â  Â  Â  Â  filter_this_stream = False
Â  Â  Â  Â  Â  Â  for line in lines:
Â  Â  Â  Â  Â  Â  Â  Â  line = line.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if not line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  if line.startswith("#EXTINF:-1"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stream_block and not filter_this_stream:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  modified_lines.extend(stream_block)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  filter_this_stream = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block = [line]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  full_stream_info = line.lower()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if any(keyword in full_stream_info for keyword in FILTER_KEYWORDS):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  filter_this_stream = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  extinf_parts = line.split(',', 1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  attributes = extinf_parts[0][len("#EXTINF:-1"):].strip()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  title = extinf_parts[1].strip() if len(extinf_parts) > 1 else "Unknown"

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # --- Force tvg-name when dummy id is used ---
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if 'tvg-id="PPV.EVENTS.Dummy.us"' in attributes:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  attributes = re.sub(r'tvg-name="[^"]*"', 'tvg-name="Live Event"', attributes)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  elif 'tvg-id=' not in attributes:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  attributes += ' tvg-name="Live Event"'

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if 'group-title=' not in attributes:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  attributes += ' group-title="Unknown"'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block[0] = f'#EXTINF:-1 {attributes},{title}'
Â  Â  Â  Â  Â  Â  Â  Â  elif not line.startswith('#'):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block.append(line)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not filter_this_stream:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  modified_lines.extend(stream_block)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  filter_this_stream = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block = []
Â  Â  Â  Â  Â  Â  Â  Â  elif stream_block:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block.append(line)
Â  Â  Â  Â  Â  Â  if stream_block and not filter_this_stream:
Â  Â  Â  Â  Â  Â  Â  Â  modified_lines.extend(stream_block)
Â  Â  Â  Â  Â  Â  print(f"âœ… Finished processing {source_name} â†’ {len(modified_lines)} lines", flush=True)
Â  Â  Â  Â  Â  Â  return "\n".join(modified_lines)
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Error fetching or processing M3U for {source_name}: {e}", flush=True)
Â  Â  Â  Â  return ""

# --- Fetch LVN with filtering and group renaming ---
async def fetch_lvn_streams(url):
Â  Â  print(f"Fetching LVN streams from {url}...", flush=True)
Â  Â  try:
Â  Â  Â  Â  async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
Â  Â  Â  Â  Â  Â  response = await client.get(url)
Â  Â  Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  Â  Â  content = response.text
Â  Â  Â  Â  Â  Â  lines = content.splitlines()
Â  Â  Â  Â  Â  Â  output_lines = ["#EXTM3U"]

Â  Â  Â  Â  Â  Â  keep_block = False
Â  Â  Â  Â  Â  Â  stream_block = []

Â  Â  Â  Â  Â  Â  for line in lines:
Â  Â  Â  Â  Â  Â  Â  Â  line = line.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if not line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  if line.startswith("#EXTINF:-1"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stream_block and keep_block:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  output_lines.extend(stream_block)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block = [line]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keep_block = False

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  channel_name = line.split(",", 1)[-1].lower()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if any(keyword.lower() in channel_name for keyword in LVN_KEYWORDS):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keep_block = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # force group-title = LVN
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if "group-title=" in line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line = re.sub(r'group-title="[^"]+"', 'group-title="LVN"', line)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line = line.replace("#EXTINF:-1", '#EXTINF:-1 group-title="LVN"', 1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block[0] = line

Â  Â  Â  Â  Â  Â  Â  Â  elif not line.startswith("#"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block.append(line)

Â  Â  Â  Â  Â  Â  if stream_block and keep_block:
Â  Â  Â  Â  Â  Â  Â  Â  output_lines.extend(stream_block)

Â  Â  Â  Â  Â  Â  print(f"âœ… LVN â†’ {len(output_lines)} lines", flush=True)
Â  Â  Â  Â  Â  Â  return "\n".join(output_lines)
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Error fetching LVN streams: {e}", flush=True)
Â  Â  Â  Â  return ""

# -----------------
# New function for ZXIPTV streams
# -----------------
async def fetch_zxiptv_streams(url):
Â  Â  print(f"Fetching ZXIPTV streams from {url}...", flush=True)
Â  Â  try:
Â  Â  Â  Â  async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
Â  Â  Â  Â  Â  Â  response = await client.get(url)
Â  Â  Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  Â  Â  content = response.text
Â  Â  Â  Â  Â  Â  lines = content.splitlines()
Â  Â  Â  Â  Â  Â  output_lines = ["#EXTM3U"]

Â  Â  Â  Â  Â  Â  stream_block = []
Â  Â  Â  Â  Â  Â  is_target_group = False
Â  Â  Â  Â  Â  Â  target_groups = ["KÃªnh 4K", "THá»‚ THAO QUá»C Táº¾"]

Â  Â  Â  Â  Â  Â  for line in lines:
Â  Â  Â  Â  Â  Â  Â  Â  line = line.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if not line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  Â  Â  if line.startswith("#EXTINF:-1"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stream_block and is_target_group:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  output_lines.extend(stream_block)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block = [line]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  is_target_group = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  match = re.search(r'group-title="([^"]+)"', line)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  original_group = match.group(1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if original_group in target_groups:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  is_target_group = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line = re.sub(r'group-title="[^"]+"', 'group-title="ZXIPTV"', line)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block[0] = line

Â  Â  Â  Â  Â  Â  Â  Â  elif not line.startswith("#"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block.append(line)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if stream_block and is_target_group:
Â  Â  Â  Â  Â  Â  Â  Â  output_lines.extend(stream_block)

Â  Â  Â  Â  Â  Â  print(f"âœ… ZXIPTV â†’ {len(output_lines)} lines", flush=True)
Â  Â  Â  Â  Â  Â  return "\n".join(output_lines)

Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Error fetching ZXIPTV streams: {e}", flush=True)
Â  Â  Â  Â  return ""

# --- Fetch BuddyChewChew stream1.m3u ---
async def fetch_bdc_streams():
Â  Â  url = "https://raw.githubusercontent.com/BuddyChewChew/My-Streams/2a46f7064f959f4098140cde484791940695fbd8/stream1.m3u"
Â  Â  print(f"Fetching BuddyChewChew streams from {url}...", flush=True)
Â  Â  try:
Â  Â  Â  Â  async with httpx.AsyncClient(timeout=30.0, follow_redirects=True) as client:
Â  Â  Â  Â  Â  Â  response = await client.get(url)
Â  Â  Â  Â  Â  Â  response.raise_for_status()
Â  Â  Â  Â  Â  Â  content = response.text
Â  Â  Â  Â  Â  Â  lines = content.splitlines()
Â  Â  Â  Â  Â  Â  output_lines = ["#EXTM3U"]

Â  Â  Â  Â  Â  Â  keep_block = False
Â  Â  Â  Â  Â  Â  stream_block = []

Â  Â  Â  Â  Â  Â  for line in lines:
Â  Â  Â  Â  Â  Â  Â  Â  line = line.strip()
Â  Â  Â  Â  Â  Â  Â  Â  if not line:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue
Â  Â  Â  Â  Â  Â  Â  Â  if line.startswith("#EXTINF:-1"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if stream_block and keep_block:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  output_lines.extend(stream_block)

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block = [line]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keep_block = False

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  channel_name = line.split(",", 1)[-1].lower()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if any(keyword in channel_name for keyword in BDC_KEYWORDS):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keep_block = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  match = re.search(r'group-title="([^"]+)"', line)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if match:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  original_group = match.group(1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  new_group = f'BDC | {original_group}'
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line = re.sub(r'group-title="[^"]+"', f'group-title="{new_group}"', line)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  line = line.replace("#EXTINF:-1", '#EXTINF:-1 group-title="BDC | Unknown"', 1)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block[0] = line

Â  Â  Â  Â  Â  Â  Â  Â  elif not line.startswith("#"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  stream_block.append(line)

Â  Â  Â  Â  Â  Â  if stream_block and keep_block:
Â  Â  Â  Â  Â  Â  Â  Â  output_lines.extend(stream_block)

Â  Â  Â  Â  Â  Â  print(f"âœ… BuddyChewChew â†’ {len(output_lines)} lines", flush=True)
Â  Â  Â  Â  Â  Â  return "\n".join(output_lines)
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Error fetching BuddyChewChew streams: {e}", flush=True)
Â  Â  Â  Â  return ""

# --- Run all scrapers sequentially ---
async def run_all_scrapers():
Â  Â  print("Starting all scrapers sequentially...", flush=True)
Â  Â  combined_results = {}

Â  Â  print("ğŸš€ Launching Playwright for StreamBTW...", flush=True)
Â  Â  async with async_playwright() as p:
Â  Â  Â  Â  browser = await p.firefox.launch(headless=True)
Â  Â  Â  Â  context = await browser.new_context(
Â  Â  Â  Â  Â  Â  user_agent="Mozilla/50 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/117.0",
Â  Â  Â  Â  Â  Â  viewport={"width": 1280, "height": 800},
Â  Â  Â  Â  Â  Â  locale="en-US"
Â  Â  Â  Â  )

Â  Â  Â  Â  scraper_list = [
Â  Â  Â  Â  Â  Â  ("StreamBTW", StreamBTW.run_streambtw)
Â  Â  Â  Â  ]

Â  Â  Â  Â  for name, func in scraper_list:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  print(f"ğŸ”¹ Starting scraper: {name}", flush=True)
Â  Â  Â  Â  Â  Â  Â  Â  combined_results[name] = await func(context)
Â  Â  Â  Â  Â  Â  Â  Â  print(f"âœ… {name} scraper finished", flush=True)
Â  Â  Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  Â  Â  print(f"âŒ {name} scraper failed: {e}", flush=True)
Â  Â  Â  Â  Â  Â  Â  Â  combined_results[name] = ""

Â  Â  Â  Â  await context.close()
Â  Â  Â  Â  await browser.close()

Â  Â  for source_name, url in NEW_SCRAPERS.items():
Â  Â  Â  Â  if source_name == "LVN":
Â  Â  Â  Â  Â  Â  combined_results[source_name] = await fetch_lvn_streams(url)
Â  Â  Â  Â  elif source_name == "ZXIPTV":
Â  Â  Â  Â  Â  Â  combined_results[source_name] = await fetch_zxiptv_streams(url)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  combined_results[source_name] = await fetch_and_process_remote_m3u(url, source_name)

Â  Â  combined_results["BuddyChewChew"] = await fetch_bdc_streams()

Â  Â  try:
Â  Â  Â  Â  combined_results["LocalChannels"] = os.environ["LocalChannels"]
Â  Â  Â  Â  print("âœ… Successfully read local channels from secret.", flush=True)
Â  Â  except KeyError:
Â  Â  Â  Â  print("âš ï¸ LocalChannels secret not found. Skipping.", flush=True)
Â  Â  Â  Â  combined_results["LocalChannels"] = ""

Â  Â  print("All scrapers finished.", flush=True)
Â  Â  return combined_results

# --- Combine and save ---
def combine_and_save_playlists(all_contents):
Â  Â  print(f"Combining and saving to '{OUTPUT_FILE_PATH}'...", flush=True)
Â  Â  full_content = "#EXTM3U\n"
Â  Â  ordered_sources = [
Â  Â  Â  Â  "LocalChannels", "A1X", "StreamBTW",
Â  Â  Â  Â  "LVN", "DDL", "BuddyChewChew", "ZXIPTV"
Â  Â  ]
Â  Â  for source_name in ordered_sources:
Â  Â  Â  Â  content = all_contents.get(source_name)
Â  Â  Â  Â  if content and content.strip():
Â  Â  Â  Â  Â  Â  full_content += f"\n# --- Content from {source_name} ---\n\n"
Â  Â  Â  Â  Â  Â  if content.startswith("#EXTM3U"):
Â  Â  Â  Â  Â  Â  Â  Â  content = content.split('\n', 1)[1] if '\n' in content else ''
Â  Â  Â  Â  Â  Â  full_content += content
Â  Â  Â  Â  Â  Â  print(f"âœ… Added content from {source_name}.", flush=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  print(f"âš ï¸ No content to add from {source_name}.", flush=True)

Â  Â  os.makedirs(OUTPUT_FILE_DIR, exist_ok=True)
Â  Â  try:
Â  Â  Â  Â  with open(OUTPUT_FILE_PATH, 'w', encoding='utf-8') as f:
Â  Â  Â  Â  Â  Â  f.write(full_content)
Â  Â  Â  Â  print(f"âœ… Saved playlist to '{OUTPUT_FILE_PATH}'.", flush=True)
Â  Â  except Exception as e:
Â  Â  Â  Â  print(f"âŒ Error saving file: {e}", flush=True)

# --- Clean up temporary files at the end of the run ---
def cleanup_temp_files():
Â  Â  try:
Â  Â  Â  Â  os.remove("StreamBTW_temp.py")
Â  Â  except OSError as e:
Â  Â  Â  Â  print(f"Error cleaning up temporary files: {e}", file=sys.stderr)

# --- Main ---
async def main():
Â  Â  combined_content = await run_all_scrapers()
Â  Â  combine_and_save_playlists(combined_content)
Â  Â  cleanup_temp_files()

if __name__ == "__main__":
Â  Â  asyncio.run(main())
